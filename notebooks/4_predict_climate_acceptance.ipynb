{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/conda/envs/datasci3/lib/python3.5/site-packages/PIL/Image.py:85: RuntimeWarning: The _imaging extension was built for another  version of Pillow or PIL\n",
      "  warnings.warn(str(v), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pyspark, pickle\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import countDistinct, regexp_replace, monotonically_increasing_id\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import CountVectorizer, StringIndexer, StopWordsRemover, NGram, RegexTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk, re\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tweets and persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = spark.read.parquet('tweets_all.parquet')\n",
    "tweets = tweets.orderBy('tweet_id').select('*', monotonically_increasing_id().alias('row'))\n",
    "tweets.persist(StorageLevel.MEMORY_AND_DISK);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean tweets for model pipeline, and run through pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Text needs to be renamed to 'tweet' for my model\n",
    "# Links need to be replace with '[link]'\n",
    "tweet_pipeline = tweets.select(regexp_replace('text', 'https?://[^ ,]+', '[link]').alias('tweet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model = PipelineModel.load('./nb_model_pipeline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc_accept_predictions = nb_model.transform(tweet_pipeline)\n",
    "cc_accept_predictions.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "cc_accept_predictions = cc_accept_predictions. \\\n",
    "    select('probability', 'prediction', monotonically_increasing_id().alias('row'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join predictions to tweets, and check results for known users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.join(cc_accept_predictions, how='left',  on='row')\n",
    "tweets.registerTempTable('tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Accept' / 'deny' classification ratio for known climate change deniers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------------+\n",
      "|screen_name    |prediction|count(prediction)|\n",
      "+---------------+----------+-----------------+\n",
      "|ClimateRealists|0.0       |413              |\n",
      "|ClimateRealists|1.0       |89               |\n",
      "+---------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 is 'accept,' 1 is 'deny'\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'ClimateRealists'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------------+\n",
      "|screen_name  |prediction|count(prediction)|\n",
      "+-------------+----------+-----------------+\n",
      "|SteveSGoddard|0.0       |139              |\n",
      "|SteveSGoddard|1.0       |62               |\n",
      "+-------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'SteveSGoddard'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------------+\n",
      "|screen_name   |prediction|count(prediction)|\n",
      "+--------------+----------+-----------------+\n",
      "|ScottAdamsSays|0.0       |22               |\n",
      "|ScottAdamsSays|1.0       |10               |\n",
      "+--------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'ScottAdamsSays'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------------+\n",
      "|screen_name|prediction|count(prediction)|\n",
      "+-----------+----------+-----------------+\n",
      "|JunkScience|0.0       |89               |\n",
      "|JunkScience|1.0       |24               |\n",
      "+-----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'JunkScience'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification ratios for known climate change acceptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------------+\n",
      "|screen_name    |prediction|count(prediction)|\n",
      "+---------------+----------+-----------------+\n",
      "|CoralMDavenport|0.0       |9                |\n",
      "|CoralMDavenport|1.0       |2                |\n",
      "+---------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 is 'accept,' 1 is 'deny'\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'CoralMDavenport'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------------+\n",
      "|screen_name|prediction|count(prediction)|\n",
      "+-----------+----------+-----------------+\n",
      "|NOAA       |0.0       |11               |\n",
      "+-----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'NOAA'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------------+\n",
      "|screen_name|prediction|count(prediction)|\n",
      "+-----------+----------+-----------------+\n",
      "|BillNye    |0.0       |12               |\n",
      "|BillNye    |1.0       |1                |\n",
      "+-----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'BillNye'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------------+\n",
      "|screen_name |prediction|count(prediction)|\n",
      "+------------+----------+-----------------+\n",
      "|EricHolthaus|0.0       |72               |\n",
      "|EricHolthaus|1.0       |11               |\n",
      "+------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select screen_name, prediction, count(prediction)\n",
    "    from tweets\n",
    "    where screen_name = 'EricHolthaus'\n",
    "    group by screen_name, prediction\n",
    "    order by prediction\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the model's behavior further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept</th>\n",
       "      <th>deny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[link]</th>\n",
       "      <td>-2.885952</td>\n",
       "      <td>-3.504653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global</th>\n",
       "      <td>-3.396628</td>\n",
       "      <td>-3.194367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warming</th>\n",
       "      <td>-3.425696</td>\n",
       "      <td>-3.194367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>-3.194328</td>\n",
       "      <td>-4.200755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>-3.208675</td>\n",
       "      <td>-4.225719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accept      deny\n",
       "[link]  -2.885952 -3.504653\n",
       "global  -3.396628 -3.194367\n",
       "warming -3.425696 -3.194367\n",
       "climate -3.194328 -4.200755\n",
       "change  -3.208675 -4.225719"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with model vocabulary and weights for each word\n",
    "\n",
    "theta = nb_model.stages[5].theta.toArray().transpose()\n",
    "model_weights = pd.DataFrame(theta, index=nb_model.stages[4].vocabulary, columns=['accept', 'deny'])\n",
    "model_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scam              0.625005\n",
       "utah              0.496431\n",
       "scandal           0.445010\n",
       "conspiracy        0.425592\n",
       "al                0.411500\n",
       "lie               0.404683\n",
       "gore              0.396014\n",
       "contradict        0.357004\n",
       "fanatics          0.357004\n",
       "#sgp              0.357004\n",
       "#teaparty         0.340909\n",
       "lol               0.331330\n",
       "fading            0.329171\n",
       "blankenship       0.329171\n",
       "anyway            0.329171\n",
       "bogus             0.329171\n",
       "fraud             0.314563\n",
       "hysteria          0.313440\n",
       "#gop              0.300363\n",
       "apparently        0.297509\n",
       "@algore           0.297509\n",
       "discredits        0.297509\n",
       "@mattyglesias     0.297509\n",
       "builds            0.297509\n",
       "irony             0.297509\n",
       "oops              0.297509\n",
       "representative    0.297509\n",
       "ass               0.297509\n",
       "#ipcc             0.297509\n",
       "yeah              0.297509\n",
       "                    ...   \n",
       "thank             0.003862\n",
       "analysis          0.003862\n",
       "shut              0.003862\n",
       "effect            0.003862\n",
       "questions         0.003862\n",
       "current           0.003862\n",
       "thanks            0.003862\n",
       "disaster          0.003862\n",
       "wednesday         0.003862\n",
       "yr                0.003862\n",
       "hear              0.003862\n",
       "full              0.003862\n",
       "abt               0.003862\n",
       "heavy             0.003862\n",
       "giving            0.003862\n",
       "@mmfa             0.003862\n",
       "2010              0.003466\n",
       "government        0.002710\n",
       "call              0.001243\n",
       "used              0.001243\n",
       "@time             0.001243\n",
       "level             0.001243\n",
       "let               0.001243\n",
       "become            0.001243\n",
       "sarah             0.001243\n",
       "increase          0.001243\n",
       "party             0.001243\n",
       "mean              0.000163\n",
       "claims            0.000163\n",
       "cause             0.000163\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate ratios for the weights of each word. Which ratios are furthest from 1?\n",
    "model_weights.apply(lambda x: abs(1-(x.accept/x.deny)), axis=1).sort_values(ascending=False)\n",
    "\n",
    "# Results look pretty good. The most predictive words look to be those used by climate change deniers.\n",
    "# The  least predictive words could plausibly be used by either side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------------------------+----------+\n",
      "|screen_name |probability                              |prediction|\n",
      "+------------+-----------------------------------------+----------+\n",
      "|EricHolthaus|[0.23493622840396688,0.7650637715960331] |1.0       |\n",
      "|EricHolthaus|[0.09120387545123637,0.9087961245487637] |1.0       |\n",
      "|EricHolthaus|[0.3490159684331323,0.6509840315668677]  |1.0       |\n",
      "|EricHolthaus|[0.01161253247199993,0.9883874675280001] |1.0       |\n",
      "|EricHolthaus|[0.019730474608470723,0.9802695253915292]|1.0       |\n",
      "|EricHolthaus|[0.3118981173583994,0.6881018826416007]  |1.0       |\n",
      "|EricHolthaus|[0.200202779648672,0.799797220351328]    |1.0       |\n",
      "|EricHolthaus|[0.39095000413382786,0.6090499958661721] |1.0       |\n",
      "|EricHolthaus|[0.07610776429816785,0.9238922357018321] |1.0       |\n",
      "|EricHolthaus|[0.25781973895784455,0.7421802610421555] |1.0       |\n",
      "|EricHolthaus|[0.3416685841640517,0.6583314158359482]  |1.0       |\n",
      "+------------+-----------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One problem with the model is that it can be very confident while being wrong\n",
    "# EricHolthaus accepts climate change, yet the model sometimes predicts 1 ('deny') with high probability\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select screen_name, probability, prediction\n",
    "    from tweets\n",
    "    where screen_name = 'EricHolthaus' and prediction = 1\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case', 'people', 'even', 'says', 'climate', 'change']\n"
     ]
    }
   ],
   "source": [
    "# Another problem: many of the words in my tweets are not in my model vocabulary\n",
    "# Take this tweet as an example, and output the words that are in the vocab:\n",
    "\n",
    "t = []\n",
    "for word in 'In which case most people are right. Not even the IPCC says climate change is \"entirely\" human-made'.split():\n",
    "    if word in nb_model.stages[4].vocabulary:\n",
    "        t.append(word)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate predictions over tweets for each user. I have a few options:\n",
    "#### 1. Use the modal prediction per user\n",
    "#### 2. Use some ratio of accept climate change/deny climate change tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modal prediction. Not very good.\n",
    "\n",
    "# predictions_per_user = spark.sql(\"\"\"\n",
    "#     select screen_name, min(prediction) as prediction\n",
    "#     from\n",
    "#         (select screen_name, prediction, count, \n",
    "#             rank() over (partition by screen_name order by count desc) as rank\n",
    "#         from \n",
    "#             (select screen_name, prediction, count(*) as count\n",
    "#             from tweets\n",
    "#             group by screen_name, prediction) sub\n",
    "#         ) sub2\n",
    "#     where rank = 1\n",
    "#     group by screen_name\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ratio-based prediction. 'Acceptors' are those who have 4 times more 'accept' tweets than 'deny'\n",
    "\n",
    "predictions_per_user = spark.sql(\"\"\"\n",
    "    select screen_name, case\n",
    "                when n_denies = 0 then 'accept'\n",
    "                when n_accepts/n_denies >= 4 then 'accept'\n",
    "                else 'deny' end as prediction\n",
    "    from\n",
    "        (select screen_name,\n",
    "            sum(case when prediction = 0 then 1 else 0 end) as n_accepts,\n",
    "            sum(case when prediction = 1 then 1 else 0 end) as n_denies\n",
    "        from tweets\n",
    "        group by screen_name\n",
    "        order by screen_name) sub\n",
    "\"\"\")\n",
    "\n",
    "# Note: these predictions didn't end up being good enough to be useful. I don't use them in my other final notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_per_user.write.parquet('user_pred.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.write.parquet('tweets_all_pred.parquet')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:datasci3]",
   "language": "python",
   "name": "conda-env-datasci3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
